{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfe84950-37bf-4755-8c28-a3bcf1ab930e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features= Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
      "       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n",
      "       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n",
      "       'Outlet_Type', 'Item_Outlet_Sales'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "linear MSE= 1908965.39\n",
      "R2= 0.33\n",
      "Index(['Item_MRP'], dtype='object')\n",
      "Coefficients= [15.7]\n",
      "Intercept= -30.89\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "\n",
    "print ('features=',train.columns)\n",
    "print ('\\n')\n",
    "\n",
    "# importing linear regressionfrom sklearn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lreg = LinearRegression()\n",
    "\n",
    "# Column valus imputation: fill in missing values with the mean \n",
    "train['Item_Weight'].fillna((train['Item_Weight'].mean()), inplace=True)\n",
    "\n",
    "X = train.loc[:,['Item_MRP']]\n",
    "#X = train.loc[:,['Outlet_Establishment_Year','Item_MRP','Item_Weight']]\n",
    "\n",
    "#splitting into training and cv for cross validation\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(X,train.Item_Outlet_Sales,test_size=0.5)\n",
    "\n",
    "#training the model\n",
    "lreg.fit(x_train,y_train)\n",
    "\n",
    "#predicting on cv\n",
    "pred = lreg.predict(x_cv)\n",
    "\n",
    "#calculating mse\n",
    "mse = np.mean((pred - y_cv)**2)\n",
    "\n",
    "r2_score(y_cv, pred)\n",
    "\n",
    "print ('linear MSE=',round(mse,2))\n",
    "print ('R2=',round(r2_score(y_cv, pred),2))\n",
    "\n",
    "# calculating coefficients\n",
    "coeff = DataFrame(x_train.columns)\n",
    "\n",
    "coeff['Coefficient Estimate'] = Series(lreg.coef_)\n",
    "\n",
    "print (X.columns)\n",
    "print ('Coefficients=',np.round(lreg.coef_,2))\n",
    "print ('Intercept=',round(lreg.intercept_,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb5d992-8c29-4c8e-bdde-ce0f2ea03946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac6937-46f1-4cb2-a50f-0fd4455295f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features= Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
      "       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n",
      "       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n",
      "       'Outlet_Type', 'Item_Outlet_Sales'],\n",
      "      dtype='object')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "\n",
    "print ('features=',train.columns)\n",
    "print ('\\n')\n",
    "\n",
    "# importing linear regressionfrom sklearn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lreg = LinearRegression()\n",
    "\n",
    "# Column valus imputation: fill in missing values with the mean \n",
    "train['Item_Weight'].fillna((train['Item_Weight'].mean()), inplace=True)\n",
    "\n",
    "#X = train.loc[:,['Item_MRP']]\n",
    "X = train.loc[:,['Outlet_Establishment_Year','Item_MRP','Item_Weight']]\n",
    "\n",
    "\n",
    "train['Outlet_Establishment_Year'] = 2013 - train['Outlet_Establishment_Year']\n",
    "\n",
    "train['Outlet_Size'].fillna('Small',inplace=True)\n",
    "\n",
    "# creating dummy variables to convert categorical into numeric values\n",
    "mylist = list(train.select_dtypes(include=['object']).columns)\n",
    "dummies = pd.get_dummies(train[mylist], prefix= mylist) \n",
    "\n",
    "train.drop(mylist, axis=1, inplace = True)\n",
    "X = pd.concat([train,dummies], axis =1 )\n",
    "\n",
    "\n",
    "#splitting into training and cv for cross validation\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(X,train.Item_Outlet_Sales,test_size=0.5)\n",
    "\n",
    "#training the model\n",
    "lreg.fit(x_train,y_train)\n",
    "\n",
    "#predicting on cv\n",
    "pred = lreg.predict(x_cv)\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(x_train)\n",
    "X_test_poly = poly_features.transform(y_train)\n",
    "\n",
    "\n",
    "#calculating mse\n",
    "mse = np.mean((pred - y_cv)**2)\n",
    "\n",
    "r2_score(y_cv, pred)\n",
    "\n",
    "print ('linear MSE=',round(mse,2))\n",
    "print ('R2=',round(r2_score(y_cv, pred),2))\n",
    "\n",
    "# calculating coefficients\n",
    "coeff = DataFrame(x_train.columns)\n",
    "\n",
    "coeff['Coefficient Estimate'] = Series(lreg.coef_)\n",
    "\n",
    "print (X.columns)\n",
    "print ('Coefficients=',np.round(lreg.coef_,2))\n",
    "print ('Intercept=',round(lreg.intercept_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca934b83-8a3c-4739-b226-da02cb7129af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cede0b87-f026-4d75-8289-16764ef34b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab8b71c2-80cd-41e1-a29b-66f01b7b8757",
   "metadata": {},
   "source": [
    "## Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65278ca-34d3-478d-a18b-2085725a2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "#import test and train file\n",
    "\n",
    "\n",
    "def multicollinearity_assumption(residuals, features):\n",
    "    \"\"\"\n",
    "    Multicollinearity: Assumes that predictors are not correlated with each other. If there is\n",
    "                       correlation among the predictors, then either remove prepdictors with high\n",
    "                       Variance Inflation Factor (VIF) values or perform dimensionality reduction\n",
    "                           \n",
    "                       This assumption being violated causes issues with interpretability of the \n",
    "                       coefficients and the standard errors of the coefficients.\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('\\n Assumption : Little to no multicollinearity among predictors')\n",
    "        \n",
    "    # Plotting the heatmap\n",
    "    plt.figure(figsize = (10,8))\n",
    "    sns.heatmap(pd.DataFrame(features).corr(), annot=True)\n",
    "    plt.title('Correlation of Variables')\n",
    "    plt.show()\n",
    "        \n",
    "    print('Variance Inflation Factors (VIF)')\n",
    "    print('> 10: An indication that multicollinearity may be present')\n",
    "    print('> 100: Certain multicollinearity among the variables')\n",
    "    print('-------------------------------------')\n",
    "       \n",
    "    # Gathering the VIF for each variable\n",
    "    VIF = [variance_inflation_factor(features, i) for i in range(features.shape[1])]\n",
    "    for idx, vif in enumerate(VIF):\n",
    "        print('idx, vif', idx, vif)\n",
    "        \n",
    "    # Gathering and printing total cases of possible or definite multicollinearity\n",
    "    possible_multicollinearity = sum([1 for vif in VIF if vif > 10])\n",
    "    definite_multicollinearity = sum([1 for vif in VIF if vif > 100])\n",
    "    print()\n",
    "    print('{0} cases of possible multicollinearity'.format(possible_multicollinearity))\n",
    "    print('{0} cases of definite multicollinearity'.format(definite_multicollinearity))\n",
    "    print()\n",
    "\n",
    "    if definite_multicollinearity == 0:\n",
    "        if possible_multicollinearity == 0:\n",
    "            print('Assumption satisfied')\n",
    "        else:\n",
    "            print('Assumption possibly satisfied')\n",
    "            print()\n",
    "            print('Coefficient interpretability may be problematic')\n",
    "            print('Consider removing variables with a high Variance Inflation Factor (VIF)')\n",
    "\n",
    "    else:\n",
    "        print('Assumption not satisfied')\n",
    "        print()\n",
    "        print('Coefficient interpretability will be problematic')\n",
    "        print('Consider removing variables with a high Variance Inflation Factor (VIF)')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normal_errors_assumption(residuals,  p_value_thresh=0.05):\n",
    "    \"\"\"\n",
    "    Normality: Assumes that the error terms are normally distributed. If they are not,\n",
    "    nonlinear transformations of variables may solve this.\n",
    "               \n",
    "    This assumption being violated primarily causes issues with the confidence intervals\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.diagnostic import normal_ad\n",
    "    print('----------------------------------------------------------------')\n",
    "\n",
    "    print('Assumption: The error terms are normally distributed', '\\n')\n",
    "    \n",
    "    \n",
    "    print('Using the Anderson-Darling test for normal distribution')\n",
    "\n",
    "    # Performing the test on the residuals\n",
    "     # Returns\n",
    "    #-------\n",
    "    #ad2 : float\n",
    "    #    Anderson Darling test statistic.\n",
    "    #pval : float\n",
    "    #    The pvalue for hypothesis that the data comes from a normal\n",
    "    #    distribution with unknown mean and variance.\n",
    "        \n",
    "    test, p_value = normal_ad(residuals)\n",
    "    print('p-value from the test - below 0.05 generally means non-normal:', p_value)\n",
    "    \n",
    "    # Reporting the normality of the residuals\n",
    "    if p_value < p_value_thresh:\n",
    "        print('Residuals are not normally distributed')\n",
    "    else:\n",
    "        print('Residuals are normally distributed')\n",
    "    \n",
    "    # Plotting the residuals distribution\n",
    "    plt.subplots(figsize=(12, 6))\n",
    "    plt.title('Distribution of Residuals')\n",
    "    #sns.histplot(residuals)\n",
    "    sns.histplot(residuals, kde=True)\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    if p_value > p_value_thresh:\n",
    "        print('Assumption satisfied')\n",
    "    else:\n",
    "        print('Assumption not satisfied')\n",
    "        print()\n",
    "        print('Confidence intervals will likely be affected')\n",
    "        print('Try performing nonlinear transformations on variables')\n",
    "\n",
    "\n",
    "def homoscedasticity_assumption(residuals):\n",
    "    \"\"\"\n",
    "    Homoscedasticity: Assumes that the errors exhibit constant variance\n",
    "    \"\"\"\n",
    "    print('\\n----------------------------------------------------')\n",
    "    print('Assumption: Homoscedasticity of Error Terms', '\\n')\n",
    "    \n",
    "    print('Residuals should have relative constant variance')\n",
    "    print('View the plot')    \n",
    "  \n",
    "    # Plotting the residuals\n",
    "    plt.subplots(figsize=(12, 6))\n",
    "    ax = plt.subplot(111)  # To remove spines\n",
    "    plt.scatter(x=np.arange(0,len(residuals)), y=residuals, alpha=0.5)\n",
    "    plt.plot(np.repeat(0, len(residuals)), color='darkorange', linestyle='--')\n",
    "    ax.spines['right'].set_visible(False)  # Removing the right spine\n",
    "    ax.spines['top'].set_visible(False)  # Removing the top spine\n",
    "    plt.title('Residuals')\n",
    "    plt.show()  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "\n",
    "# importing linear regressionfrom sklearn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lreg = LinearRegression()\n",
    "\n",
    "#splitting into training and cv for cross validation\n",
    "train['Item_Weight'].fillna((train['Item_Weight'].mean()), inplace=True)\n",
    "\n",
    "X = train.loc[:,['Outlet_Establishment_Year','Item_MRP','Item_Weight']]\n",
    "# = train.loc[:,['Item_MRP']]\n",
    "\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(X,train.Item_Outlet_Sales,test_size=0.5)\n",
    "\n",
    "#training the model\n",
    "\n",
    "lreg.fit(x_train,y_train)\n",
    "\n",
    "#predicting on cv\n",
    "\n",
    "pred = lreg.predict(x_cv)\n",
    "\n",
    "#calculating mse\n",
    "\n",
    "mse = np.mean((pred - y_cv)**2)\n",
    "\n",
    "\n",
    "r2_score(y_cv, pred)\n",
    "\n",
    "print ('MSE=',mse)\n",
    "print ('R2=',r2_score(y_cv, pred))\n",
    "\n",
    "\n",
    "\n",
    "# calculating coefficients\n",
    "coeff = DataFrame(x_train.columns)\n",
    "\n",
    "coeff['Coefficient Estimate'] = Series(lreg.coef_)\n",
    "\n",
    "\n",
    "print ('Coefficients=',lreg.coef_)\n",
    "print ('Intercept=',lreg.intercept_)\n",
    "\n",
    "\n",
    "residuals = (y_cv - pred)\n",
    "\n",
    "#Test the assumption, about the normal distribution of errors\n",
    "normal_errors_assumption(residuals)\n",
    "\n",
    "#Test the assumption of homescedacity\n",
    "homoscedasticity_assumption(residuals)\n",
    "\n",
    "#test the assumption of multicollinearity\n",
    "multicollinearity_assumption(residuals, np.array(X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9e574-dae1-4bcd-9159-ea2e64317ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
