{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2cb80bc-bbe8-407b-b449-9e276d14a4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short data report:\n",
      "#classes= 2\n",
      "Class-1 #number of samples= 151\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m a\u001b[38;5;241m=\u001b[39mY\u001b[38;5;241m.\u001b[39mgroupby(Y)\u001b[38;5;241m.\u001b[39mcount()\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass-1 #number of samples=\u001b[39m\u001b[38;5;124m'\u001b[39m,a[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass-2 #number of samples=\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m)    \n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m#convert pandas data to numpy array\u001b[39;00m\n\u001b[1;32m     81\u001b[0m X\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(X)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jan 30 05:34:19 2018\n",
    "\n",
    "@author: acggs\n",
    "\n",
    "Test multiple classifiers on a dataset\n",
    "\"\"\"\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import datasets \n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "data=pd.read_csv('wpbc.data',header=None)\n",
    "\n",
    "\n",
    "Y=data[1]\n",
    "\n",
    "\n",
    "# N, R are the two classes\n",
    "Y.replace('N',1,inplace=True)\n",
    "Y.replace('R',0,inplace=True)\n",
    "\n",
    "\n",
    "X=data.iloc[:,2:]\n",
    "\n",
    "# the following is a ?, i.e. a missing value\n",
    "#x.iloc[196][34]\n",
    "#replace it with a numpy nan\n",
    "X=X.replace('?',np.NaN)\n",
    "\n",
    "#x[34].loc[196]=x[34].median()\n",
    "X[34].fillna(X[34].median(),inplace=True)\n",
    "\n",
    "\n",
    "# make all columns with 0-mean, and 1-std\n",
    "X = preprocessing.scale(x)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"gini\", random_state=0)\n",
    "\n",
    "\n",
    "print ('Short data report:')\n",
    "print('#classes=',len(Y.unique()))\n",
    "a=Y.groupby(Y).count()\n",
    "print('Class-1 #number of samples=',a[1])\n",
    "print('Class-2 #number of samples=',a[2])    \n",
    "\n",
    "\n",
    "#convert pandas data to numpy array\n",
    "X=np.array(X)\n",
    "\n",
    "#print dimensions of the data\n",
    "nRows, nCols = X.shape\n",
    "print ('#Data samples=',nRows)\n",
    "print ('#Data attributes=',nCols-1)   \n",
    "print('------------------------------------------')\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# Percentage of data to use in training: 50%\n",
    "# The rest will be used for testing\n",
    "\n",
    "\n",
    "\n",
    "####  Data set separated intro training and testing ####\n",
    "# Training set to build the classifier will be 50% of the data\n",
    "# number of data attribute=4 (indexed from 0 to 3)\n",
    " #class label is the last column (indexed by 4)\n",
    "\n",
    "\n",
    "train_size=0.5  # 50 per cent of the data\n",
    "print(\"Percentage used in training:\", train_size)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X[:,0:4], X[:,4], train_size=0.50, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "###  Training #####\n",
    "#Actual training of the classifier\n",
    "#training data followed by labels\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "\n",
    "###  Tesing #####\n",
    "#test the trained model on the training set\n",
    "Y_train_pred=clf.predict(X_train)\n",
    "\n",
    "#test the trained model on the test set\n",
    "Y_test_pred=clf.predict(X_test)\n",
    "\n",
    "#produce confusin matrix on the training data\n",
    "confMatrixTrain=confusion_matrix(Y_train, Y_train_pred, labels=None)\n",
    "\n",
    "#produce confusin matrix on the TESTING data\n",
    "confMatrixTest=confusion_matrix(Y_test, Y_test_pred, labels=None)\n",
    "\n",
    "\n",
    "\n",
    "### Evaluation ###\n",
    "# Evaluation on accuracy: training, testing set\n",
    "print ('\\tClassifier Evaluation')\n",
    "print ('Accuracy Train=', accuracy_score(Y_train, Y_train_pred, normalize=True))\n",
    "print ('Accuracy Test=', accuracy_score(Y_test, Y_test_pred, normalize=True))\n",
    "print()\n",
    "\n",
    "# Evaluation on Confusion matrix: training, testing set\n",
    "print ('Confusion matrix train')\n",
    "print (confMatrixTrain,'\\n')\n",
    "print ('Confusion matrix test')\n",
    "print (confMatrixTest)\n",
    "print ()\n",
    "\n",
    "# Measures of performance: Precision, Recall, F1\n",
    "# Macro: \n",
    "print('Macro-train f1=',f1_score(Y_train, Y_train_pred, average='macro')) \n",
    "print('Macro-test f1=',f1_score(Y_test, Y_test_pred, average='macro')) \n",
    "print()\n",
    "# Micro: \n",
    "print('Micro-train f1=',f1_score(Y_train, Y_train_pred, average='micro')) \n",
    "print('Micro-test f1=',f1_score(Y_test, Y_test_pred, average='micro')) \n",
    "print()\n",
    "print('train f1 per class=',f1_score(Y_train, Y_train_pred, average=None))\n",
    "print('test_f1 per class =',f1_score(Y_test, Y_test_pred, average=None)) \n",
    "print()\n",
    "#\n",
    "print ('Macro: train-Precision-Recall-FScore-Support',precision_recall_fscore_support(Y_train, Y_train_pred, average='macro'))\n",
    "print ('Macro: test-Precision-Recall-FScore-Support',precision_recall_fscore_support(Y_test, Y_test_pred, average='macro'))\n",
    "print ('\\n')\n",
    "print ('\\n')\n",
    "\n",
    "\n",
    "#the Decision tree is stored in the current directory\n",
    "# to see the actual tree paste to .dot file to\n",
    "# http://www.webgraphviz.com/  \n",
    "tree.export_graphviz(clf, out_file='iris-tree.dot',class_names=['setosa','versicolor','virginica'])\n",
    "#\n",
    "print('Tree rules=\\n',tree.export_text(clf,feature_names=['sepal_length','petal_width']))\n",
    "# Some statistics on the Tree:\n",
    "print('Max Depth=',clf.get_depth())\n",
    "print('Number of Leaves=',clf.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390dbe14-8df3-4a2e-912f-2d25640e053a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
